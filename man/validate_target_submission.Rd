% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/validate_target_submission.R
\name{validate_target_submission}
\alias{validate_target_submission}
\title{Validate a submitted target data file.}
\usage{
validate_target_submission(
  hub_path,
  file_path,
  target_type = c("time-series", "oracle-output"),
  date_col = NULL,
  allow_extra_dates = FALSE,
  round_id = "default",
  na = c("NA", ""),
  output_type_id_datatype = c("from_config", "auto", "character", "double", "integer",
    "logical", "Date"),
  validations_cfg_path = NULL,
  skip_check_config = FALSE
)
}
\arguments{
\item{hub_path}{Either a character string path to a local Modeling Hub directory
or an object of class \verb{<SubTreeFileSystem>} created using functions \code{\link[hubData:s3_bucket]{s3_bucket()}}
or \code{\link[hubData:gs_bucket]{gs_bucket()}} by providing a string S3 or GCS bucket name or path to a
Modeling Hub directory stored in the cloud.
For more details consult the
\href{https://arrow.apache.org/docs/r/articles/fs.html}{Using cloud storage (S3, GCS)}
in the \code{arrow} package.
The hub must be fully configured with valid \code{admin.json} and \code{tasks.json}
files within the \code{hub-config} directory.}

\item{file_path}{A character string representing the path to the target data
file relative to the \code{target-data} directory.}

\item{target_type}{Type of target data to retrieve matching files. One of "time-series" or
"oracle-output". Defaults to "time-series".}

\item{date_col}{Optional name of the column containing the date observations
actually occurred (e.g., \code{"target_end_date"}) to be interpreted as date.
Useful when this column does not correspond to a valid task ID (e.g.,
calculated from other task IDs like \code{origin_date + horizon}) for: (1) correct
schema creation, particularly when it's also a partitioning column, and (2)
more robust column name validation when \code{target-data.json} config does not
exist. Ignored when \code{target-data.json} exists.}

\item{allow_extra_dates}{Logical. If TRUE and target_type is
"time-series", allows date values not in tasks.json. Other task ID columns
are still strictly validated. Ignored for oracle-output (always strict).}

\item{round_id}{Character string. Not generally relevant to target datasets
but can be used to specify a specific block of custom validation checks.
Otherwise best set to \code{"default"} which will deploy the default custom
validation checks.}

\item{na}{A character vector of strings to interpret as missing values. Only
applies to CSV files. The default is \code{c("NA", "")}. Useful when actual character
string \code{"NA"} values are used in the data. In such a case, use empty cells to
indicate missing values in your files and set \code{na = ""}.}

\item{output_type_id_datatype}{character string. One of \code{"from_config"}, \code{"auto"},
\code{"character"}, \code{"double"}, \code{"integer"}, \code{"logical"}, \code{"Date"}.
Defaults to \code{"from_config"} which uses the setting in the \code{output_type_id_datatype}
property in the \code{tasks.json} config file if available. If the property is
not set in the config, the argument falls back to \code{"auto"} which determines
the  \code{output_type_id} data type automatically from the \code{tasks.json}
config file as the simplest data type required to represent all output
type ID values across all output types in the hub.
When only point estimate output types (where \code{output_type_id}s are \code{NA},) are
being collected by a hub, the \code{output_type_id} column is assigned a \code{character}
data type when auto-determined.
Other data type values can be used to override automatic determination.
Note that attempting to coerce \code{output_type_id} to a data type that is
not valid for the data (e.g. trying to coerce\code{"character"} values to
\code{"double"}) will likely result in an error or potentially unexpected
behaviour so use with care.}

\item{validations_cfg_path}{Path to YAML file configuring custom validation checks.
If \code{NULL} defaults to standard \code{hub-config/validations.yml} path. For more details
see \href{https://hubverse-org.github.io/hubValidations/articles/deploying-custom-functions.html}{article on custom validation checks}.}

\item{skip_check_config}{Logical. Whether to skip the hub config validation check.}
}
\value{
An object of class \code{hub_validations}. Each named element contains
a \code{hub_check} class object reflecting the result of a given check. Function
will return early if a check returns an error.

For more details on the structure of \verb{<hub_validations>} objects, including
how to access more information on individual checks,
see \href{https://hubverse-org.github.io/hubValidations/articles/hub-validations-class.html}{article on \verb{<hub_validations>} S3 class objects}.
}
\description{
Checks both file level properties like
file name, extension, location etc as well as target data, i.e. the
contents of the file.
}
\details{
Details of checks performed by \code{validate_target_submission()}\if{html}{\out{
<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">
 <thead>
  <tr>
   <th style="text-align:left;"> Name </th>
   <th style="text-align:left;"> Check </th>
   <th style="text-align:left;"> Early return </th>
   <th style="text-align:left;"> Fail output </th>
   <th style="text-align:left;"> Extra info </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;font-weight: bold;"> valid_config </td>
   <td style="text-align:left;"> Hub config valid </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_exists </td>
   <td style="text-align:left;"> File exists at `file_path` provided. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_partition_file_name </td>
   <td style="text-align:left;"> Hive-style partition file path segments are valid and can be parsed successfully. Skipped if target dataset not hive-partitioned. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_ext </td>
   <td style="text-align:left;"> Target data file extension is valid. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_read </td>
   <td style="text-align:left;"> Target data file can be read successfully. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_colnames </td>
   <td style="text-align:left;"> Target data file has the correct column names according to target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_coltypes </td>
   <td style="text-align:left;"> Target data file has the correct column types according to target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_ts_targets </td>
   <td style="text-align:left;"> Targets in a time-series target data file are valid. Only performed on `time-series` data files. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_rows_unique </td>
   <td style="text-align:left;"> Target data file rows are all unique. </td>
   <td style="text-align:left;"> FALSE </td>
   <td style="text-align:left;"> check_failure </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_values </td>
   <td style="text-align:left;"> Task ID columns in a target data file have valid task ID values. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_output_type_ids </td>
   <td style="text-align:left;"> Output type ID values in a target data file are valid and complete. Only performed when the target data file contains an `output_type_id` column. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_oracle_value </td>
   <td style="text-align:left;"> Oracle values in a target data file are valid. Only performed on `oracle output` data files. </td>
   <td style="text-align:left;"> FALSE </td>
   <td style="text-align:left;"> check_failure </td>
   <td style="text-align:left;">  </td>
  </tr>
</tbody>
</table>
}}
}
\examples{
hub_path <- system.file("testhubs/v5/target_file", package = "hubUtils")
validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series"
)
# Example with partitioned data
hub_path <- system.file("testhubs/v5/target_dir", package = "hubUtils")
validate_target_submission(
  hub_path,
  file_path = "time-series/target=flu_hosp_rate/part-0.parquet",
  target_type = "time-series"
)
}
