% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/check_target_dataset_rows_unique.R
\name{check_target_dataset_rows_unique}
\alias{check_target_dataset_rows_unique}
\title{Check target dataset rows are all unique}
\usage{
check_target_dataset_rows_unique(
  target_type = c("time-series", "oracle-output"),
  na = c("NA", ""),
  date_col = NULL,
  output_type_id_datatype = c("from_config", "auto", "character", "double", "integer",
    "logical", "Date"),
  hub_path
)
}
\arguments{
\item{target_type}{Type of target data to retrieve matching files. One of "time-series" or
"oracle-output". Defaults to "time-series".}

\item{na}{A character vector of strings to interpret as missing values. Only
applies to CSV files. The default is \code{c("NA", "")}. Useful when actual character
string \code{"NA"} values are used in the data. In such a case, use empty cells to
indicate missing values in your files and set \code{na = ""}.}

\item{date_col}{Optional column name to be interpreted as date. Default is \code{NULL}.
Useful when the required date column is a partitioning column in the target data
and does not have the same name as a date typed task ID variable in the config.}

\item{output_type_id_datatype}{character string. One of \code{"from_config"}, \code{"auto"},
\code{"character"}, \code{"double"}, \code{"integer"}, \code{"logical"}, \code{"Date"}.
Defaults to \code{"from_config"} which uses the setting in the \code{output_type_id_datatype}
property in the \code{tasks.json} config file if available. If the property is
not set in the config, the argument falls back to \code{"auto"} which determines
the  \code{output_type_id} data type automatically from the \code{tasks.json}
config file as the simplest data type required to represent all output
type ID values across all output types in the hub.
When only point estimate output types (where \code{output_type_id}s are \code{NA},) are
being collected by a hub, the \code{output_type_id} column is assigned a \code{character}
data type when auto-determined.
Other data type values can be used to override automatic determination.
Note that attempting to coerce \code{output_type_id} to a data type that is
not valid for the data (e.g. trying to coerce\code{"character"} values to
\code{"double"}) will likely result in an error or potentially unexpected
behaviour so use with care.}

\item{hub_path}{Either a character string path to a local Modeling Hub directory
or an object of class \verb{<SubTreeFileSystem>} created using functions \code{\link[hubData:s3_bucket]{s3_bucket()}}
or \code{\link[hubData:gs_bucket]{gs_bucket()}} by providing a string S3 or GCS bucket name or path to a
Modeling Hub directory stored in the cloud.
For more details consult the
\href{https://arrow.apache.org/docs/r/articles/fs.html}{Using cloud storage (S3, GCS)}
in the \code{arrow} package.
The hub must be fully configured with valid \code{admin.json} and \code{tasks.json}
files within the \code{hub-config} directory.}
}
\value{
Depending on whether validation has succeeded, one of:
\itemize{
\item \verb{<message/check_success>} condition class object.
\item \verb{<error/check_failure>} condition class object.
}

Returned object also inherits from subclass \verb{<hub_check>}.
}
\description{
Check that there are no duplicate rows in a target dataset.
Function designed to be used as part of overall target data integrity check.
}
\details{
If datasets are versioned, multiple observations are allowed in \code{time-series}
target data, so long as they have different \code{as_of} values. The \code{as_of} column
is therefore included when determining duplicates.
In \code{oracle-output} data, there should be only a single observation,
regardless of the \code{as_of} value so the column it is not be included when
determining duplicates.
}
