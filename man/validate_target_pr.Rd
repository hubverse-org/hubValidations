% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/validate_target_pr.R
\name{validate_target_pr}
\alias{validate_target_pr}
\title{Validate Target Data Pull Request}
\usage{
validate_target_pr(
  hub_path = ".",
  gh_repo,
  pr_number,
  output_type_id_datatype = c("from_config", "auto", "character", "double", "integer",
    "logical", "Date"),
  date_col = NULL,
  allow_extra_dates = FALSE,
  na = c("NA", ""),
  round_id = "default",
  validations_cfg_path = NULL,
  file_modification_check = c("none", "message", "failure", "error"),
  allow_target_type_deletion = FALSE
)
}
\arguments{
\item{hub_path}{Either a character string path to a local Modeling Hub directory
or an object of class \verb{<SubTreeFileSystem>} created using functions \code{\link[hubData:s3_bucket]{s3_bucket()}}
or \code{\link[hubData:gs_bucket]{gs_bucket()}} by providing a string S3 or GCS bucket name or path to a
Modeling Hub directory stored in the cloud.
For more details consult the
\href{https://arrow.apache.org/docs/r/articles/fs.html}{Using cloud storage (S3, GCS)}
in the \code{arrow} package.
The hub must be fully configured with valid \code{admin.json} and \code{tasks.json}
files within the \code{hub-config} directory.}

\item{gh_repo}{GitHub repository address in the format \code{username/repo}}

\item{pr_number}{Number of the pull request to validate}

\item{output_type_id_datatype}{character string. One of \code{"from_config"}, \code{"auto"},
\code{"character"}, \code{"double"}, \code{"integer"}, \code{"logical"}, \code{"Date"}.
Defaults to \code{"from_config"} which uses the setting in the \code{output_type_id_datatype}
property in the \code{tasks.json} config file if available. If the property is
not set in the config, the argument falls back to \code{"auto"} which determines
the  \code{output_type_id} data type automatically from the \code{tasks.json}
config file as the simplest data type required to represent all output
type ID values across all output types in the hub.
When only point estimate output types (where \code{output_type_id}s are \code{NA},) are
being collected by a hub, the \code{output_type_id} column is assigned a \code{character}
data type when auto-determined.
Other data type values can be used to override automatic determination.
Note that attempting to coerce \code{output_type_id} to a data type that is
not valid for the data (e.g. trying to coerce\code{"character"} values to
\code{"double"}) will likely result in an error or potentially unexpected
behaviour so use with care.}

\item{date_col}{Optional name of the column containing the date observations
actually occurred (e.g., \code{"target_end_date"}) to be interpreted as date.
Useful when this column does not correspond to a valid task ID (e.g.,
calculated from other task IDs like \code{origin_date + horizon}) for: (1) correct
schema creation, particularly when it's also a partitioning column, and (2)
more robust column name validation when \code{target-data.json} config does not
exist. Ignored when \code{target-data.json} exists.}

\item{allow_extra_dates}{Logical. If TRUE and target_type is
"time-series", allows date values not in tasks.json. Other task ID columns
are still strictly validated. Ignored for oracle-output (always strict).}

\item{na}{A character vector of strings to interpret as missing values. Only
applies to CSV files. The default is \code{c("NA", "")}. Useful when actual character
string \code{"NA"} values are used in the data. In such a case, use empty cells to
indicate missing values in your files and set \code{na = ""}.}

\item{round_id}{Character string. Not generally relevant to target datasets
but can be used to specify a specific block of custom validation checks.
Otherwise best set to \code{"default"} which will deploy the default custom
validation checks.}

\item{validations_cfg_path}{Path to YAML file configuring custom validation checks.
If \code{NULL} defaults to standard \code{hub-config/validations.yml} path. For more details
see \href{https://hubverse-org.github.io/hubValidations/articles/deploying-custom-functions.html}{article on custom validation checks}.}

\item{file_modification_check}{Character string. Whether to perform check and what to
return when modification/deletion of a previously submitted target data file is detected in PR:
\itemize{
\item \code{"none"}: No modification/deletion checks performed.
\item \code{"message"}: Appends a \verb{<message/check_info>} condition class object for each
applicable modified/deleted file.
\item \code{"failure"}: Appends a \verb{<error/check_failure>} condition class object for each
applicable modified/deleted file.
\item \code{"error"}: Appends a \verb{<error/check_error>} condition class object for each
applicable modified/deleted file.
}

Defaults to \verb{"none}".}

\item{allow_target_type_deletion}{Logical. Whether to allow deletion of an entire
target type dataset (i.e. all files of a target type) in the PR. Defaults to \code{FALSE}.}
}
\value{
An object of class \code{target_validations}.
}
\description{
Validates target data files in a Pull Request.
}
\details{
Only target data files are individually validated using
\code{validate_target_submission()} although as part of checks, hub config files and
any affected target type datasets as a whole are also validated via
\code{validate_target_dataset()}.
Any other files included in the PR are ignored but flagged in a message.

By default, modifications (which include renaming) and deletions of
previously submitted target data files are allowed.
This behaviour can be modified through
arguments \code{file_modification_check}, which controls whether modification/deletion
checks are performed and what is returned if modifications/deletions are detected.
\subsection{Checks on target dataset}{

Details of checks performed by \code{validate_target_dataset()}\if{html}{\out{<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">}}\if{html}{\out{
 <thead>
  <tr>
   <th style="text-align:left;"> Name </th>
   <th style="text-align:left;"> Check </th>
   <th style="text-align:left;"> Early return </th>
   <th style="text-align:left;"> Fail output </th>
   <th style="text-align:left;"> Extra info </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;font-weight: bold;"> valid_config </td>
   <td style="text-align:left;"> Hub config valid </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_dataset_exists </td>
   <td style="text-align:left;"> Target dataset can be successfully detected for a given target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_dataset_unique </td>
   <td style="text-align:left;"> A single unique target dataset exists for a given target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_dataset_file_ext_unique </td>
   <td style="text-align:left;"> All files of a given target type share a single unique file format. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_dataset_rows_unique </td>
   <td style="text-align:left;"> Target dataset rows are all unique. </td>
   <td style="text-align:left;"> FALSE </td>
   <td style="text-align:left;"> check_failure </td>
   <td style="text-align:left;">  </td>
  </tr>
</tbody>
</table>
}}

}

\subsection{Checks on individual target files}{

Details of checks performed by \code{validate_target_submission()}\if{html}{\out{<table class="table table-striped table-hover table-condensed table-responsive" style="margin-left: auto; margin-right: auto;">}}\if{html}{\out{
 <thead>
  <tr>
   <th style="text-align:left;"> Name </th>
   <th style="text-align:left;"> Check </th>
   <th style="text-align:left;"> Early return </th>
   <th style="text-align:left;"> Fail output </th>
   <th style="text-align:left;"> Extra info </th>
   <th style="text-align:left;"> optional </th>
  </tr>
 </thead>
<tbody>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_exists </td>
   <td style="text-align:left;"> File exists at `file_path` provided. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_partition_file_name </td>
   <td style="text-align:left;"> Hive-style partition file path segments are valid and can be parsed successfully. Skipped if target dataset not hive-partitioned. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_ext </td>
   <td style="text-align:left;"> Target data file extension is valid. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_file_read </td>
   <td style="text-align:left;"> Target data file can be read successfully. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_colnames </td>
   <td style="text-align:left;"> Target data file has the correct column names according to target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_coltypes </td>
   <td style="text-align:left;"> Target data file has the correct column types according to target type. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_ts_targets </td>
   <td style="text-align:left;"> Targets in a time-series target data file are valid. Only performed on `time-series` data files. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_rows_unique </td>
   <td style="text-align:left;"> Target data file rows are all unique. </td>
   <td style="text-align:left;"> FALSE </td>
   <td style="text-align:left;"> check_failure </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_values </td>
   <td style="text-align:left;"> Task ID columns in a target data file have valid task ID values. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_output_type_ids </td>
   <td style="text-align:left;"> Output type ID values in a target data file are valid and complete. Only performed when the target data file contains an `output_type_id` column. </td>
   <td style="text-align:left;"> TRUE </td>
   <td style="text-align:left;"> check_error </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
  <tr>
   <td style="text-align:left;font-weight: bold;"> target_tbl_oracle_value </td>
   <td style="text-align:left;"> Oracle values in a target data file are valid. Only performed on `oracle output` data files. </td>
   <td style="text-align:left;"> FALSE </td>
   <td style="text-align:left;"> check_failure </td>
   <td style="text-align:left;">  </td>
   <td style="text-align:left;"> FALSE </td>
  </tr>
</tbody>
</table>
}}

}
}
\examples{
\dontrun{
tmp_dir <- withr::local_tempdir()
ci_target_hub_path <- fs::path(tmp_dir, "target")
gert::git_clone(
  url = "https://github.com/hubverse-org/ci-testhub-target.git",
  path = ci_target_hub_path
)
# Validate addition of single file in single file target dataset
gert::git_branch_checkout(
  "add-file-oracle-output",
  repo = ci_target_hub_path
)
validate_target_pr(
  hub_path = ci_target_hub_path,
  gh_repo = "hubverse-org/ci-testhub-target",
  pr_number = 1
)
# Validate addition of multiple files in partitioned target dataset
gert::git_branch_checkout(
  "add-target-dir-files-v5",
  repo = ci_target_hub_path
)
validate_target_pr(
  hub_path = ci_target_hub_path,
  gh_repo = "hubverse-org/ci-testhub-target",
  pr_number = 2
)
}
}
