---
title: "Validating hub data locally"
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(hubValidations)
```

While most hubs will have automated validation systems set up to check contributions via Pull Requests, `hubValidations` also provides functionality for validating files locally before submitting them.

This article covers local validation of:

- [**Model output files**](#validating-model-output-files-with-validate_submission) using `validate_submission()`
- [**Model metadata files**](#validating-model-metadata-files-with-validate_model_metadata) using `validate_model_metadata()`
- [**Target data files**](#validating-target-data-files-with-validate_target_submission) using `validate_target_submission()` and `validate_target_dataset()`

## Validating model output files with `validate_submission()`

**Submitting teams can use `validate_submission()` to validate their model output files prior to submitting.**

The function takes a relative path, relative to the model output directory, as argument `file_path`, performs a series of standard validation checks and returns their results in the form of a `hub_validations` S3 class object.

```{r}
hub_path <- system.file("testhubs/simple", package = "hubValidations")

validate_submission(hub_path,
  file_path = "team1-goodmodel/2022-10-08-team1-goodmodel.csv"
)
```

For more details on the structure of `<hub_validations>` objects, including how to access more information on individual checks, see `vignette("articles/hub-validations-class")`.

### Validation early return

**Some checks which are critical to downstream checks will cause validation to stop and return the results of the checks up to and including the critical check that failed early.**

They generally return a `<error/check_error>` condition class object.
Any problems identified will need to be resolved and the function re-run for validation to proceed further.


```{r}
hub_path <- system.file("testhubs/simple", package = "hubValidations")

validate_submission(hub_path,
  file_path = "team1-goodmodel/2022-10-15-hub-baseline.csv"
)
```

### Execution Errors

If an execution error occurs in any of the checks, an `<error/check_exec_error>` is returned instead. For validation purposes, this results in the same downstream effects as an `<error/check_error>` object.


### Checking for errors with `check_for_errors()`

You can check whether your file will overall pass validation checks by passing the `hub_validations` object to `check_for_errors()`. 

If validation fails, an error will be thrown and the failing checks will be summarised.

```{r, error=TRUE}
validate_submission(hub_path,
  file_path = "team1-goodmodel/2022-10-08-team1-goodmodel.csv"
)  |>
  check_for_errors()
```



### Skipping the submission window check

If you are preparing your submission prior to the submission window opening, you might want to skip the submission window check.
You can so by setting argument `skip_submit_window_check` to `TRUE`. 

This results in the previous valid file (except for failing the validation window check) now passing overall validation.

```{r}
validate_submission(hub_path,
  file_path = "team1-goodmodel/2022-10-08-team1-goodmodel.csv",
  skip_submit_window_check = TRUE
)  |>
  check_for_errors()
```

### Ignoring derived task IDs to improve validation performance

#### What are derived task IDs?

Derived task IDs are a class of task ID whose values depend on the values of other task IDs. As such, the **validity of derived task ID values is dependent on the values of the task IDs they are derived from** and the validity of value combinations of derived and other task IDs is much more restricted. A common example of a derived task ID is `target_end_date` which is most often derived from the `reference_date` or `origin_date` and `horizon` task ids. 

#### How to ignore derived task IDs

<div class="alert alert-info" role="note">

**For configs using schema version v4.0.0 and above, derived task IDs are configured via the hub config and do not need to be ignored manually**

To check if the hub uses schema version v4.0.0 or above, you can use:
```r
hubUtils::version_gte("v4.0.0", hub_path = "path/to/hub")
```

</div>

Argument **`derived_task_ids`** allows for the specification of **task IDs that are derived from other task IDs**. Supplying the names of derived task IDs to argument `derived_task_ids` will ignore them during validation checks.

Depending on config complexity, this **can often lead to a significant improvement in validation performance and in some circumstances is necessary for correct validation**.

<div class="alert alert-warning" role="note">

Note that, **if any task IDs with `required` values have dependent derived task IDs, it is essential for `derived_task_ids` to be specified**. 
If this is the case and derived task IDs are not specified, the dependent nature of derived task ID values will result in **false validation errors when validating required values**.

If you're unsure if this is the case for your hub or which task IDs are derived, please consult the hub documentation or contact the hub administrators.

</div>

### `validate_submission` check details

```{r, echo=FALSE}
library(kableExtra)
arrow::read_csv_arrow(system.file("check_table.csv", package = "hubValidations"))  |>
  dplyr::filter(
    .data$`parent fun` != "validate_model_metadata",
    !.data$optional
  )  |>
  dplyr::select(-"parent fun", -"check fun", -"optional")  |>
  dplyr::mutate("Extra info" = dplyr::case_when(
    is.na(.data$`Extra info`) ~ "",
    TRUE ~ .data$`Extra info`
  ))  |>
  knitr::kable(caption = "Details of checks performed by `validate_submission()`")  |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  |>
  column_spec(1, bold = TRUE)
```


## Validating model metadata files with `validate_model_metadata()`

If you want to check a model metadata file before submitting, you can similarly use function `validate_model_metadata()`.

The function takes model metadata file name as argument `file_path`, performs a series of validation checks and returns their results in the form of a `hub_validations` S3 class object.

```{r}
validate_model_metadata(hub_path,
  file_path = "hub-baseline.yml"
)

validate_model_metadata(hub_path,
  file_path = "team1-goodmodel.yaml"
)
```


For more details on the structure of `<hub_validations>` objects, including how to access more information on individual checks, see `vignette("articles/hub-validations-class")`.

### `validate_model_metadata` check details

```{r, echo=FALSE}
library(kableExtra)
arrow::read_csv_arrow(system.file("check_table.csv", package = "hubValidations"))  |>
  dplyr::filter(
    .data$`parent fun` == "validate_model_metadata",
    !.data$optional
  )  |>
  dplyr::select(-"parent fun", -"check fun", -"optional")  |>
  dplyr::mutate("Extra info" = dplyr::case_when(
    is.na(.data$`Extra info`) ~ "",
    TRUE ~ .data$`Extra info`
  ))  |>
  knitr::kable(caption = "Details of checks performed by `validate_model_metadata()`")  |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  |>
  column_spec(1, bold = TRUE)
```


## Validating target data files with `validate_target_submission()`

Target data files can also be validated locally before submitting using `validate_target_submission()`.

The function validates both file-level properties (file name, extension, location) and the contents of the target data file. It takes a relative path (relative to the `target-data` directory) as argument `file_path` and the `target_type` (either `"time-series"` or `"oracle-output"`).

### Configuring target data validation

For the most robust validation, hubs should include a `target-data.json` configuration file in their `hub-config` directory (available from schema version 6.0.0 onwards). When present, this config provides deterministic validation by explicitly defining the date column, column names and types, and observable unit structure.

For hubs without a `target-data.json` config, the **`date_col`** parameter can be used to specify the name of the column containing observation dates (e.g., `"target_end_date"`). This is important for correct schema creation, particularly when the date column is also used for partitioning. When `target-data.json` exists, any user-provided `date_col` is ignored in favour of the config value.

### Single file target datasets

For hubs with single file target datasets (e.g., `target-data/time-series.csv`):

```{r}
hub_path <- system.file("testhubs/v6/target_file", package = "hubUtils")

validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series"
)
```

```{r}
validate_target_submission(
  hub_path,
  file_path = "oracle-output.csv",
  target_type = "oracle-output"
)
```

### Partitioned target datasets

For hubs with partitioned target datasets stored as directories:

```{r}
hub_path <- system.file("testhubs/v6/target_dir", package = "hubUtils")

validate_target_submission(
  hub_path,
  file_path = "time-series/target=wk%20flu%20hosp%20rate/part-0.parquet",
  target_type = "time-series"
)
```

### Relaxed date validation for time-series data

By default, date values in time-series target data are validated strictly against the dates defined in `tasks.json`. However, target data often contains historical observations with dates beyond the hub's configured modeling rounds.

Setting **`allow_extra_dates = TRUE`** relaxes date validation for time-series data, allowing historical observations while still strictly validating other task ID values. Oracle-output data always uses strict date validation regardless of this setting.

Here's an example demonstrating this feature. First, we create a copy of a hub and add a row with a date not defined in `tasks.json`:

```{r}
# Create a temporary copy of the hub
tmp_hub <- withr::local_tempdir()
fs::dir_copy(
  system.file("testhubs/v5/target_file", package = "hubUtils"),
  tmp_hub
)
hub_path <- fs::path(tmp_hub, "target_file")

# Read the time-series data and add a row with an extra date
ts_data <- read.csv(fs::path(hub_path, "target-data", "time-series.csv"))
extra_row <- ts_data[1, ]
extra_row$target_end_date <- "1999-01-01"
ts_data <- rbind(extra_row, ts_data)
write.csv(ts_data, fs::path(hub_path, "target-data", "time-series.csv"), row.names = FALSE)
```

With the default `allow_extra_dates = FALSE`, validation fails because the date is not in `tasks.json`:

```{r, error=TRUE}
v <- validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series",
  date_col = "target_end_date"
)
v
```

Setting `allow_extra_dates = TRUE` allows the extra date while still validating other task IDs:

```{r}
v <- validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series",
  date_col = "target_end_date",
  allow_extra_dates = TRUE
)
v
```

Note the message indicating the date column was excluded from validation.

### Validating without a `target-data.json` config

For hubs without a `target-data.json` config (e.g., v5 hubs), you can specify the date column manually:

```{r}
hub_path <- system.file("testhubs/v5/target_file", package = "hubUtils")

validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series",
  date_col = "target_end_date"
)
```

### Validating the entire target dataset

To validate dataset-level properties across all files of a target type, use `validate_target_dataset()`:

```{r}
hub_path <- system.file("testhubs/v6/target_file", package = "hubUtils")

validate_target_dataset(hub_path, target_type = "time-series")

validate_target_dataset(hub_path, target_type = "oracle-output")
```

This checks that the dataset exists, is unique, has consistent file extensions, and contains unique rows across all files.

### Checking for errors with `check_for_errors()`

You can use `check_for_errors()` to determine whether validation passed or failed overall.

For successful validation:

```{r}
hub_path <- system.file("testhubs/v6/target_file", package = "hubUtils")

v <- validate_target_submission(
  hub_path,
  file_path = "time-series.csv",
  target_type = "time-series"
)
check_for_errors(v)
```

When validation fails, `check_for_errors()` throws an error summarising the failing checks:

```{r, error=TRUE}
# Using the modified hub from the allow_extra_dates example above
v_fail <- validate_target_submission(
  fs::path(tmp_hub, "target_file"),
  file_path = "time-series.csv",
  target_type = "time-series",
  date_col = "target_end_date"
)
check_for_errors(v_fail)
```

### `validate_target_submission` check details

```{r, echo=FALSE}
arrow::read_csv_arrow(system.file("check_table.csv", package = "hubValidations"))  |>
  dplyr::filter(
    .data$`parent fun` %in% c(
      "validate_target_file",
      "validate_target_data"
    ),
    !.data$optional
  )  |>
  dplyr::select(-"parent fun", -"check fun", -"optional")  |>
  dplyr::mutate("Extra info" = dplyr::case_when(
    is.na(.data$`Extra info`) ~ "",
    TRUE ~ .data$`Extra info`
  ))  |>
  knitr::kable(caption = "Details of checks performed by `validate_target_submission()`")  |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  |>
  column_spec(1, bold = TRUE)
```

### `validate_target_dataset` check details

```{r, echo=FALSE}
arrow::read_csv_arrow(system.file("check_table.csv", package = "hubValidations"))  |>
  dplyr::filter(
    .data$`parent fun` == "validate_target_dataset",
    !.data$optional
  )  |>
  dplyr::select(-"parent fun", -"check fun", -"optional")  |>
  dplyr::mutate("Extra info" = dplyr::case_when(
    is.na(.data$`Extra info`) ~ "",
    TRUE ~ .data$`Extra info`
  ))  |>
  knitr::kable(caption = "Details of checks performed by `validate_target_dataset()`")  |>
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))  |>
  column_spec(1, bold = TRUE)
```


<div class="alert alert-info" role="note">

#### Custom checks

The standard checks discussed here are the checks deployed by default by the `validate_submission`, `validate_model_metadata`, `validate_target_submission` and `validate_target_dataset` functions.
For more information on deploying optional/custom functions or functions that require configuration please check the article on [including custom functions](deploying-custom-functions.html) (`vignette("articles/deploying-custom-functions")`).

</div>
